{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c34b0ee7-47cf-4986-a247-f4e7fec5cdba",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eae52de1-be4b-432b-ae7c-9ca259317660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from llama_index.core import VectorStoreIndex, ServiceContext\n",
    "from llama_index.core.settings import Settings\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine # para crear una query_engine con un retriever específico.\n",
    "from llama_index.core.evaluation import RetrieverEvaluator\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# Carga del texto limpio\n",
    "data_path = \"../data/plain_text/plain_text.txt\"\n",
    "\n",
    "with open(data_path, \"r\", encoding = \"utf-8\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Export boolean\n",
    "export_csv = False\n",
    "\n",
    "# Key\n",
    "load_dotenv()\n",
    "\n",
    "# Set model llm\n",
    "llm = OpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "Settings.llm = llm\n",
    "\n",
    "# Set embedding model\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70eaa5c-0a78-4f5c-85b3-273a486854dd",
   "metadata": {},
   "source": [
    "# Def function to create Score DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "662924dd-0b60-48eb-b909-dc8bef917c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function aux\n",
    "def get_responses_similarity(query_str, query_engine, top_k):\n",
    "    \"Extraer la información de los nodos devueltos por el motor de consulta al lanzar la query.\"\n",
    "    response = query_engine.query(query_str)\n",
    "\n",
    "    info_nodes = {\n",
    "        \"query\" : [query_str] * top_k,\n",
    "        \"position_node\": [],\n",
    "        \"node_content\": [],\n",
    "        \"node_score\": [],\n",
    "        \"response\" : [response] * top_k\n",
    "    }\n",
    "    for i, node_with_score in enumerate(response.source_nodes):\n",
    "        info_nodes[\"node_content\"].append(node_with_score.node.get_content())\n",
    "        info_nodes[\"node_score\"].append(node_with_score.score)\n",
    "        info_nodes[\"position_node\"].append(i+1)\n",
    "\n",
    "    return info_nodes\n",
    "\n",
    "def create_score_DataFrame(\n",
    "    content_text,\n",
    "    chunk_sizes,\n",
    "    chunk_overlap = 20,\n",
    "    top_k = 10,\n",
    "    save_storage = False,\n",
    "    load_storage = False,\n",
    "    storage_path = \"../data/index_storage/\",\n",
    "    queries = []\n",
    "): \n",
    "    \"Almacenar de forma ordenada los resultados de las distintas pruebas de chunk_size. \"\n",
    "    pdf_doc = Document(text = content.strip())\n",
    "    all_rows = []\n",
    "\n",
    "    for chunk_size in chunk_sizes: # para cada valor de prueba de tamaño de nodo\n",
    "        # se realiza la división con dicho tamaño de nodo\n",
    "        parser = SimpleNodeParser().from_defaults(chunk_size = chunk_size, chunk_overlap = chunk_overlap)\n",
    "        nodes = parser.get_nodes_from_documents([pdf_doc])\n",
    "\n",
    "        # se realiza el embedding para el funcionamiento del retriever\n",
    "        Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "        index = VectorStoreIndex(nodes)\n",
    "        \n",
    "        ## Save or Load Storage #####  --------------------------------------------------------------------\n",
    "        if save_storage:\n",
    "            index.storage_context.persist(persist_dir=\"../data/index_storage/\")\n",
    "        if load_storage:\n",
    "            storage_context = StorageContext.from_defaults(\n",
    "                docstore=SimpleDocumentStore.from_persist_dir(persist_dir=\"../data/index_storage/\"),\n",
    "                vector_store=SimpleVectorStore.from_persist_dir(\n",
    "                    persist_dir=\"data/index_storage/\"\n",
    "                ),\n",
    "                index_store=SimpleIndexStore.from_persist_dir(persist_dir=\"../data/index_storage/\"),\n",
    "            )\n",
    "        ## ------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # Retriever -- definición y ejecución sobre varias queries pasadas con el argumento queries\n",
    "        retriever = index.as_retriever(similarity_top_k=top_k) # antes query_engine usaba k=2\n",
    "        query_engine_VSI = RetrieverQueryEngine.from_args(retriever=retriever)\n",
    "    \n",
    "        # Get nodes with score\n",
    "        chunk_size_rows = []\n",
    "        for query in queries:\n",
    "            query_info = get_responses_similarity(query, query_engine = query_engine_VSI, top_k=top_k)\n",
    "            # Añadir chunk_size como metadato adicional para la comprobación \n",
    "            query_info[\"chunk_size\"] = [chunk_size] * top_k\n",
    "            query_info[\"chunk_overlap\"] = [chunk_overlap] * top_k\n",
    "            chunk_df = pd.DataFrame(query_info)\n",
    "            all_rows.append(chunk_df)\n",
    "\n",
    "    # End of chunk_size loop\n",
    "    score_df = pd.concat(all_rows, ignore_index = True)\n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cafd2b6-c2f5-4697-aeba-d30a4f48b988",
   "metadata": {},
   "source": [
    "# Test on differents sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cf59ac3-92a8-4459-bdbc-5ec0be32e163",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chunk_sizes = [200, 300, 500]\n",
    "queries = [\n",
    "    \"What does collect() function do in pyspark?\",\n",
    "    \"What is the role of the Driver component?\",\n",
    "    \"What does a 'broadcast join' mean?\",\n",
    "    \"How does persist() differ from cache() in PySpark?\"\n",
    "]\n",
    "\n",
    "score_df = create_score_DataFrame(\n",
    "    content_text=content,\n",
    "    chunk_sizes=chunk_sizes,\n",
    "    top_k=5,\n",
    "    queries=queries\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5a76333-c935-4395-a957-cdb62fbdcf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_df.to_csv(\"../data/scores_retriever/scores_by_chunksize.csv\", sep = \";\") -- revisar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc631229-fcb6-414b-aaae-f41e2528453a",
   "metadata": {},
   "source": [
    "### Resumen de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84bb9470-96d3-48d7-a5f2-25ef4ac0c706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_score_retriever(df):\n",
    "    agg1 = df.groupby(\"chunk_size\")[\"node_score\"].mean().reset_index()\n",
    "    agg1.columns = [\"chunk_size\", \"mean_score_all_positions\"]\n",
    "\n",
    "    agg2 = df[df[\"position_node\"] == 1].groupby(\"chunk_size\")[\"node_score\"].mean().reset_index()\n",
    "    agg2.columns = [\"chunk_size\", \"mean_score_top1\"]\n",
    "    result = pd.merge(agg1, agg2, on=\"chunk_size\")\n",
    "    return result.sort_values(\"chunk_size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f79144b-5a3c-4297-9332-b614c5aced3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_size</th>\n",
       "      <th>mean_score_all_positions</th>\n",
       "      <th>mean_score_top1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>0.568016</td>\n",
       "      <td>0.629079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300</td>\n",
       "      <td>0.520839</td>\n",
       "      <td>0.588275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>0.480259</td>\n",
       "      <td>0.575582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chunk_size  mean_score_all_positions  mean_score_top1\n",
       "0         200                  0.568016         0.629079\n",
       "1         300                  0.520839         0.588275\n",
       "2         500                  0.480259         0.575582"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_score_retriever(score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d55e0e-501a-4d61-828d-c91b2a1dc351",
   "metadata": {},
   "source": [
    "A menor chunk_size mayor score, o eso parece ser la tendencia. Vamos a probar chunk_size más finos para ver, por ejemplo 100, 150. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "766c031f-b8bd-4895-b87e-43055fb0515c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_sizes = [100, 150, 200]\n",
    "\n",
    "score_df = create_score_DataFrame(\n",
    "    content_text=content,\n",
    "    chunk_sizes=chunk_sizes,\n",
    "    top_k=5,\n",
    "    queries=queries\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81b2ed3c-7e60-44a6-abe1-8b5e4ab215c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_size</th>\n",
       "      <th>mean_score_all_positions</th>\n",
       "      <th>mean_score_top1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.576822</td>\n",
       "      <td>0.618374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>0.572786</td>\n",
       "      <td>0.607733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>0.568125</td>\n",
       "      <td>0.628987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chunk_size  mean_score_all_positions  mean_score_top1\n",
       "0         100                  0.576822         0.618374\n",
       "1         150                  0.572786         0.607733\n",
       "2         200                  0.568125         0.628987"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_score_retriever(score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a66e6c6-6cd4-469a-887e-00bd82d2d1bc",
   "metadata": {},
   "source": [
    "# Exportar los resultados del mejor chunk_size (sin prueba de chunk_overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3e5130-9f65-49aa-bb1e-9ec365474fa2",
   "metadata": {},
   "source": [
    "```\n",
    "pdf_doc = Document(text=content.strip())\n",
    "\n",
    "# Parsear el documento en nodos con chunking optimizado\n",
    "chunk_size = 200\n",
    "chunk_overlap = 20\n",
    "\n",
    "parser = SimpleNodeParser().from_defaults(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "nodes = parser.get_nodes_from_documents([pdf_doc])\n",
    "\n",
    "# Definir el modelo de embeddings definitivo\n",
    "# Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Crear el índice final\n",
    "index = VectorStoreIndex(nodes)\n",
    "\n",
    "# Persistir el índice final para el pipeline RAG\n",
    "storage_path = \"../data/index_storage/\"\n",
    "index.storage_context.persist(persist_dir=storage_path)\n",
    "\n",
    "print(\"✅ VectorStoreIndex final creado y guardado correctamente en:\", storage_path)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88070c05-b452-4245-8c42-7b36a950c285",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "```\n",
    "#Tests with that index_storage\n",
    "retriever= index.as_retriever(similarity_top_k =5)\n",
    "query = \"What does collect() function do in PySpark?\"\n",
    "nodes = retriever.retrieve(query)\n",
    "query_engine =  RetrieverQueryEngine.from_args(retriever=retriever)\n",
    "response = query_engine.query(query)\n",
    "\n",
    "# 6️⃣ Mostrar los chunks devueltos\n",
    "print(f\"\\nConsulta: {query}\\n{'='*60}\")\n",
    "\n",
    "for i, node in enumerate(response.source_nodes):\n",
    "    print(f\"\\n--- Nodo {i+1} ---\")\n",
    "    print(f\"Score: {node.score:.4f}\")\n",
    "    print(node.node.get_content())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbec80f-a84e-463f-993e-4c5c1ad3d3e9",
   "metadata": {},
   "source": [
    "# Iterar entre chunk_size y chunk_overlap -- PRUEBA FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52331271-49d5-4c32-8eff-c63b261ae4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_score_DataFrame_v2(\n",
    "    content_text,\n",
    "    chunk_sizes,\n",
    "    chunk_overlaps,\n",
    "    top_k = 10,\n",
    "    save_storage = False,\n",
    "    load_storage = False,\n",
    "    storage_path = \"../data/index_storage/\",\n",
    "    queries = []\n",
    "): \n",
    "    \"\"\"Almacenar de forma ordenada los resultados de las distintas pruebas de chunk_size y chunk_overlap.\"\"\"\n",
    "\n",
    "    pdf_doc = Document(text=content_text.strip())\n",
    "    all_rows = []\n",
    "\n",
    "    # Generamos todas las combinaciones de chunk_size y chunk_overlap\n",
    "    combinations = list(itertools.product(chunk_sizes, chunk_overlaps))\n",
    "\n",
    "    for chunk_size, chunk_overlap in combinations:\n",
    "        # División de documentos con cada combinación\n",
    "        parser = SimpleNodeParser().from_defaults(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "        nodes = parser.get_nodes_from_documents([pdf_doc])\n",
    "\n",
    "        # Embedding para el funcionamiento del retriever\n",
    "        Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "        index = VectorStoreIndex(nodes)\n",
    "        \n",
    "        ## Save or Load Storage #####  \n",
    "        if save_storage:\n",
    "            index.storage_context.persist(persist_dir=storage_path)\n",
    "        if load_storage:\n",
    "            storage_context = StorageContext.from_defaults(\n",
    "                docstore=SimpleDocumentStore.from_persist_dir(persist_dir=storage_path),\n",
    "                vector_store=SimpleVectorStore.from_persist_dir(persist_dir=storage_path),\n",
    "                index_store=SimpleIndexStore.from_persist_dir(persist_dir=storage_path),\n",
    "            )\n",
    "        ## ------------------------------------------------------------\n",
    "\n",
    "        # Retriever y evaluación de queries\n",
    "        retriever = index.as_retriever(similarity_top_k=top_k)\n",
    "        query_engine_VSI = RetrieverQueryEngine.from_args(retriever=retriever)\n",
    "    \n",
    "        for query in queries:\n",
    "            query_info = get_responses_similarity(query, query_engine=query_engine_VSI, top_k=top_k)\n",
    "            query_info[\"chunk_size\"] = [chunk_size] * top_k\n",
    "            query_info[\"chunk_overlap\"] = [chunk_overlap] * top_k\n",
    "            chunk_df = pd.DataFrame(query_info)\n",
    "            all_rows.append(chunk_df)\n",
    "\n",
    "    # Unimos resultados de todas las pruebas\n",
    "    score_df = pd.concat(all_rows, ignore_index=True)\n",
    "    return score_df\n",
    "\n",
    "def analyze_score_retriever_v2(df):\n",
    "    \"\"\"\n",
    "    Calcula métricas agregadas de node_score agrupando por chunk_size y chunk_overlap.\n",
    "    \"\"\"\n",
    "    # Media de todos los nodos recuperados (todas las posiciones)\n",
    "    agg1 = df.groupby([\"chunk_size\", \"chunk_overlap\"])[\"node_score\"].mean().reset_index()\n",
    "    agg1.columns = [\"chunk_size\", \"chunk_overlap\", \"mean_score_all_positions\"]\n",
    "\n",
    "    # Media solo del top-1 (posición 1)\n",
    "    agg2 = df[df[\"position_node\"] == 1].groupby([\"chunk_size\", \"chunk_overlap\"])[\"node_score\"].mean().reset_index()\n",
    "    agg2.columns = [\"chunk_size\", \"chunk_overlap\", \"mean_score_top1\"]\n",
    "\n",
    "    # Unimos ambos resultados\n",
    "    result = pd.merge(agg1, agg2, on=[\"chunk_size\", \"chunk_overlap\"])\n",
    "\n",
    "    # Ordenamos para mejor lectura\n",
    "    return result.sort_values([\"chunk_size\", \"chunk_overlap\"]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5634ca0c-5079-41ef-91be-12c6024a7e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_sizes = [150, 200, 300, 500]\n",
    "chunk_overlaps = [20, 50, 90]\n",
    "queries = [\n",
    "    \"What does collect() function do in pyspark?\",\n",
    "    \"What is the role of the Driver component?\",\n",
    "    \"What does a 'broadcast join' mean?\"\n",
    "]\n",
    "df_scores = create_score_DataFrame_v2(\n",
    "    content_text=content,\n",
    "    chunk_sizes=chunk_sizes,\n",
    "    chunk_overlaps=chunk_overlaps,\n",
    "    top_k=5,\n",
    "    queries=queries\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89bf25a3-38d4-4b1b-94dd-cbb4571992be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_scores.to_csv(\"../data/scores_retriever/scores_by_chunksize_chunkoverlap.csv\", sep = \";\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "422f49ff-ee62-42c9-88e2-6679b96a6797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_size</th>\n",
       "      <th>chunk_overlap</th>\n",
       "      <th>mean_score_all_positions</th>\n",
       "      <th>mean_score_top1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150</td>\n",
       "      <td>90</td>\n",
       "      <td>0.570297</td>\n",
       "      <td>0.620202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>90</td>\n",
       "      <td>0.555730</td>\n",
       "      <td>0.609322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>20</td>\n",
       "      <td>0.548184</td>\n",
       "      <td>0.589283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>0.545805</td>\n",
       "      <td>0.603085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>0.541294</td>\n",
       "      <td>0.589623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>0.541042</td>\n",
       "      <td>0.609723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>300</td>\n",
       "      <td>90</td>\n",
       "      <td>0.527067</td>\n",
       "      <td>0.607967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>0.519124</td>\n",
       "      <td>0.593811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>300</td>\n",
       "      <td>20</td>\n",
       "      <td>0.497696</td>\n",
       "      <td>0.558183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>500</td>\n",
       "      <td>90</td>\n",
       "      <td>0.486329</td>\n",
       "      <td>0.541210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>0.484048</td>\n",
       "      <td>0.535597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>0.465270</td>\n",
       "      <td>0.539168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chunk_size  chunk_overlap  mean_score_all_positions  mean_score_top1\n",
       "2          150             90                  0.570297         0.620202\n",
       "5          200             90                  0.555730         0.609322\n",
       "0          150             20                  0.548184         0.589283\n",
       "4          200             50                  0.545805         0.603085\n",
       "1          150             50                  0.541294         0.589623\n",
       "3          200             20                  0.541042         0.609723\n",
       "8          300             90                  0.527067         0.607967\n",
       "7          300             50                  0.519124         0.593811\n",
       "6          300             20                  0.497696         0.558183\n",
       "11         500             90                  0.486329         0.541210\n",
       "10         500             50                  0.484048         0.535597\n",
       "9          500             20                  0.465270         0.539168"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = analyze_score_retriever_v2(df_scores)\n",
    "results.sort_values([\"mean_score_all_positions\", \"mean_score_top1\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c875285-da82-44fd-8260-488b9a659cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ VectorStoreIndex final creado y guardado correctamente en: data/index_storage_200_90/\n"
     ]
    }
   ],
   "source": [
    "# exportar el 200, 90. \n",
    "pdf_doc = Document(text=content.strip())\n",
    "\n",
    "# Parsear el documento en nodos con chunking optimizado\n",
    "chunk_size = 200\n",
    "chunk_overlap = 90\n",
    "\n",
    "parser = SimpleNodeParser().from_defaults(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "nodes = parser.get_nodes_from_documents([pdf_doc])\n",
    "\n",
    "# Definir el modelo de embeddings definitivo\n",
    "# Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Crear el índice final\n",
    "index = VectorStoreIndex(nodes)\n",
    "\n",
    "# Persistir el índice final para el pipeline RAG\n",
    "storage_path = \"../data/index_storage/\"\n",
    "index.storage_context.persist(persist_dir=storage_path)\n",
    "\n",
    "print(\"✅ VectorStoreIndex final creado y guardado correctamente en:\", storage_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
